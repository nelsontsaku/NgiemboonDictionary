{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "from collections import defaultdict, Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tsakunelson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling letter 'a' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=a&lang=en\n",
      "Crawling letter 'a' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=a&lang=en\n",
      "Crawling letter 'a' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=a&lang=en\n",
      "Crawling letter 'b' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=b&lang=en\n",
      "Crawling letter 'b' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=b&lang=en\n",
      "Crawling letter 'b' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=b&lang=en\n",
      "Crawling letter 'c' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=c&lang=en\n",
      "Crawling letter 'c' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=c&lang=en\n",
      "Crawling letter 'c' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=c&lang=en\n",
      "Crawling letter 'd' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=d&lang=en\n",
      "Crawling letter 'd' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=d&lang=en\n",
      "Crawling letter 'd' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=d&lang=en\n",
      "Crawling letter 'e' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=e&lang=en\n",
      "Crawling letter 'e' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=e&lang=en\n",
      "Crawling letter 'e' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=e&lang=en\n",
      "Crawling letter 'f' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=f&lang=en\n",
      "Crawling letter 'f' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=f&lang=en\n",
      "Crawling letter 'f' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=f&lang=en\n",
      "Crawling letter 'g' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=g&lang=en\n",
      "Crawling letter 'g' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=g&lang=en\n",
      "Crawling letter 'g' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=g&lang=en\n",
      "Crawling letter 'h' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=h&lang=en\n",
      "Crawling letter 'h' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=h&lang=en\n",
      "Crawling letter 'h' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=h&lang=en\n",
      "Crawling letter 'i' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=i&lang=en\n",
      "Crawling letter 'i' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=i&lang=en\n",
      "Crawling letter 'i' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=i&lang=en\n",
      "Crawling letter 'j' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=j&lang=en\n",
      "Crawling letter 'j' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=j&lang=en\n",
      "Crawling letter 'j' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=j&lang=en\n",
      "Crawling letter 'k' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=k&lang=en\n",
      "Crawling letter 'k' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=k&lang=en\n",
      "Crawling letter 'k' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=k&lang=en\n",
      "Crawling letter 'l' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=l&lang=en\n",
      "Crawling letter 'l' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=l&lang=en\n",
      "Crawling letter 'l' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=l&lang=en\n",
      "Crawling letter 'm' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=m&lang=en\n",
      "Crawling letter 'm' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=m&lang=en\n",
      "Crawling letter 'm' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=m&lang=en\n",
      "Crawling letter 'n' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=n&lang=en\n",
      "Crawling letter 'n' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=n&lang=en\n",
      "Crawling letter 'n' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=n&lang=en\n",
      "Crawling letter 'o' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=o&lang=en\n",
      "Crawling letter 'o' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=o&lang=en\n",
      "Crawling letter 'o' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=o&lang=en\n",
      "Crawling letter 'p' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=p&lang=en\n",
      "Crawling letter 'p' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=p&lang=en\n",
      "Crawling letter 'p' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=p&lang=en\n",
      "Crawling letter 'q' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=q&lang=en\n",
      "Crawling letter 'q' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=q&lang=en\n",
      "Crawling letter 'q' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=q&lang=en\n",
      "Crawling letter 'r' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=r&lang=en\n",
      "Crawling letter 'r' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=r&lang=en\n",
      "Crawling letter 'r' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=r&lang=en\n",
      "Crawling letter 's' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=s&lang=en\n",
      "Crawling letter 's' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=s&lang=en\n",
      "Crawling letter 's' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=s&lang=en\n",
      "Crawling letter 't' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=t&lang=en\n",
      "Crawling letter 't' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=t&lang=en\n",
      "Crawling letter 't' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=t&lang=en\n",
      "Crawling letter 'u' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=u&lang=en\n",
      "Crawling letter 'u' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=u&lang=en\n",
      "Crawling letter 'u' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=u&lang=en\n",
      "Crawling letter 'v' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=v&lang=en\n",
      "Crawling letter 'v' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=v&lang=en\n",
      "Crawling letter 'v' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=v&lang=en\n",
      "Crawling letter 'w' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=w&lang=en\n",
      "Crawling letter 'w' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=w&lang=en\n",
      "Crawling letter 'w' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=w&lang=en\n",
      "Crawling letter 'x' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=x&lang=en\n",
      "Crawling letter 'x' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=x&lang=en\n",
      "Crawling letter 'x' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=x&lang=en\n",
      "Crawling letter 'y' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=y&lang=en\n",
      "Crawling letter 'y' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=y&lang=en\n",
      "Crawling letter 'y' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=y&lang=en\n",
      "Crawling letter 'z' for language 'francais'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/francais/?letter=z&lang=en\n",
      "Crawling letter 'z' for language 'english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/english/?letter=z&lang=en\n",
      "Crawling letter 'z' for language 'browse-vernacular-english'...\n",
      "Crawling: https://www.webonary.org/ngiemboon/browse/browse-vernacular-english/?letter=z&lang=en\n",
      "Data saved to ngiemboon_dictionary_full.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "class NgiemboonDictionaryScraper:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.domain = self.extract_domain(base_url)\n",
    "        self.crawled_pages = set()\n",
    "        self.to_crawl = []\n",
    "        self.dictionary_data = []\n",
    "\n",
    "    def extract_domain(self, url):\n",
    "        \"\"\"Extract the domain from a URL.\"\"\"\n",
    "        match = re.match(r'(https?://)?(www\\d?\\.)?(?P<domain>[\\w.-]+\\.\\w+)', url)\n",
    "        return match.group('domain') if match else None\n",
    "\n",
    "    def fetch_page(self, url):\n",
    "        \"\"\"Fetch the HTML content of a page.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            if response.status_code == 200:\n",
    "                return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def extract_links(self, html):\n",
    "        \"\"\"Extract all links from a page.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        return links\n",
    "\n",
    "    def canonicalize_url(self, url):\n",
    "        \"\"\"Convert a relative URL to an absolute URL.\"\"\"\n",
    "        return urljoin(self.base_url, url)\n",
    "\n",
    "    def is_within_browse_directory(self, url):\n",
    "        \"\"\"Check if the URL is within the /browse/ directory.\"\"\"\n",
    "        return \"/browse/\" in url\n",
    "\n",
    "    def extract_dictionary_data(self, html):\n",
    "        \"\"\"Extract dictionary entries from a page.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        entries = []\n",
    "\n",
    "        # Find all dictionary entries\n",
    "        for entry in soup.select('.reversalindexentry'):\n",
    "            # Extract the French or English word (first occurrence of lang=\"fr\" or lang=\"en\")\n",
    "            current_language = None\n",
    "            word = None\n",
    "            ngiemboon_word = None\n",
    "            example_usage = []\n",
    "\n",
    "            # Extract the word based on the first occurrence of lang=\"fr\" or lang=\"en\"\n",
    "            for lang_tag in entry.find_all(['span', 'a'], attrs={'lang': True}):\n",
    "                if lang_tag['lang'] == 'fr':\n",
    "                    current_language = \"French\"\n",
    "                    word = lang_tag.text.strip()\n",
    "                    break\n",
    "                elif lang_tag['lang'] == 'en':\n",
    "                    current_language = \"English\"\n",
    "                    word = lang_tag.text.strip()\n",
    "                    break\n",
    "\n",
    "            # Extract Ngiemboon words and example usage\n",
    "            for lang_tag in entry.find_all(['span', 'a'], attrs={'lang': 'nnh'}):\n",
    "                ngiemboon_word = lang_tag.text.strip()\n",
    "                example_usage.append(ngiemboon_word)\n",
    "\n",
    "            # Combine example usage into a single string\n",
    "            example_usage = \" \".join(example_usage)\n",
    "\n",
    "            if current_language and word and ngiemboon_word:\n",
    "                entries.append({\n",
    "                    \"Current Language Category\": current_language,\n",
    "                    \"word\": word,\n",
    "                    \"Ngienmboon Language word\": ngiemboon_word,\n",
    "                    \"Example Usage\": example_usage\n",
    "                })\n",
    "\n",
    "        return entries\n",
    "\n",
    "    def crawl(self, letter, language):\n",
    "        \"\"\"Crawl the website for a specific letter and language.\"\"\"\n",
    "        start_url = f\"{self.base_url}/browse/{language}/?letter={letter}&lang=en\"\n",
    "        self.to_crawl = [start_url]\n",
    "\n",
    "        while self.to_crawl:\n",
    "            url = self.to_crawl.pop(0)\n",
    "            if url in self.crawled_pages:\n",
    "                continue\n",
    "            print(f\"Crawling: {url}\")\n",
    "            html = self.fetch_page(url)\n",
    "            if not html:\n",
    "                continue\n",
    "            self.crawled_pages.add(url)\n",
    "\n",
    "            # Extract dictionary data from the page\n",
    "            entries = self.extract_dictionary_data(html)\n",
    "            self.dictionary_data.extend(entries)\n",
    "\n",
    "            # Extract and add new links to the crawl list (for pagination)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            pagination_links = soup.select('#wp_page_numbers a')\n",
    "            for link in pagination_links:\n",
    "                full_link = self.canonicalize_url(link['href'])\n",
    "                if self.is_within_browse_directory(full_link) and full_link not in self.crawled_pages:\n",
    "                    self.to_crawl.append(full_link)\n",
    "\n",
    "            time.sleep(1)  # Politeness delay\n",
    "\n",
    "    def save_to_json(self, filename):\n",
    "        \"\"\"Save the extracted data to a JSON file.\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.dictionary_data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.webonary.org/ngiemboon\"\n",
    "    scraper = NgiemboonDictionaryScraper(base_url)\n",
    "\n",
    "    # Define letters and languages to crawl\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    languages = [\"francais\", \"english\", \"browse-vernacular-english\"]\n",
    "\n",
    "    # Crawl for each letter and language\n",
    "    for letter in letters:\n",
    "        for language in languages:\n",
    "            print(f\"Crawling letter '{letter}' for language '{language}'...\")\n",
    "            scraper.crawl(letter, language)\n",
    "\n",
    "    # Save the collected data to a JSON file\n",
    "    scraper.save_to_json(\"ngiemboon_dictionary_full.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in the JSON file: 548\n",
      "\n",
      "First few entries:\n",
      "\n",
      "Entry 1:\n",
      "Current Language Category: French\n",
      "word: Ã \n",
      "Ngienmboon Language word: lÃ©\n",
      "Example Usage: lÃ©- Ã¡1 Ã¡ nÃ©2 nÃ© mbwÃ³ pÃ 1 pÃ  lÃ©1 lÃ©\n",
      "\n",
      "Entry 2:\n",
      "Current Language Category: French\n",
      "word: Ã  (+verbe)\n",
      "Ngienmboon Language word: Ã©-\n",
      "Example Usage: á¸¿-1 á¸¿- Å„-1 Å„- Ã©-1 Ã©-\n",
      "\n",
      "Entry 3:\n",
      "Current Language Category: French\n",
      "word: abaisser\n",
      "Ngienmboon Language word: Å„kwÉ”gte\n",
      "Example Usage: Å„kwÉ”g1 Å„kwÉ”g Å„kwÉ”gte1 Å„kwÉ”gte\n",
      "\n",
      "Entry 4:\n",
      "Current Language Category: French\n",
      "word: abandon\n",
      "Ngienmboon Language word: tÃ©m nzÃ¨m\n",
      "Example Usage: tÃ©m nzÃ¨m\n",
      "\n",
      "Entry 5:\n",
      "Current Language Category: French\n",
      "word: abandonner\n",
      "Ngienmboon Language word: Å„kyÃ©\n",
      "Example Usage: Å„nyÃ©2 Å„nyÃ© Å„kyÃ©\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def explore_json_output(file_path, num_entries=5):\n",
    "    \"\"\"\n",
    "    Explore and display the contents of a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "        num_entries (int): Number of entries to display. Default is 5.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the JSON file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Print the total number of entries\n",
    "        print(f\"Total entries in the JSON file: {len(data)}\")\n",
    "\n",
    "        # Display the first few entries\n",
    "        print(\"\\nFirst few entries:\")\n",
    "        for i, entry in enumerate(data[:num_entries], 1):\n",
    "            print(f\"\\nEntry {i}:\")\n",
    "            for key, value in entry.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file '{file_path}' is not a valid JSON file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file_path = \"ngiemboon_dictionary_full.json\"  # Replace with your JSON file path\n",
    "    explore_json_output(json_file_path, num_entries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entry(french_word):\n",
    "    for entry in data:\n",
    "        if entry[\"word\"].lower() == french_word.lower():\n",
    "            return entry\n",
    "    return \"Word not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in the JSON file: 548\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the JSON file\n",
    "    with open(\"ngiemboon_dictionary_full.json\", 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # Print the total number of entries\n",
    "    print(f\"Total entries in the JSON file: {len(data)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: The file '{file_path}' is not a valid JSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word not found\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "french_word = \"balance\"\n",
    "result = find_entry(french_word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– Scraping category: French\n",
      "  ğŸ”¤ Scraping letter: a (24 pages, 584 entries)\n",
      "    ğŸ“„ Scraping page 1 of 24\n",
      "    ğŸ“„ Scraping page 2 of 24\n",
      "    ğŸ“„ Scraping page 3 of 24\n",
      "    ğŸ“„ Scraping page 4 of 24\n",
      "    ğŸ“„ Scraping page 5 of 24\n",
      "    ğŸ“„ Scraping page 6 of 24\n",
      "    ğŸ“„ Scraping page 7 of 24\n",
      "    ğŸ“„ Scraping page 8 of 24\n",
      "    ğŸ“„ Scraping page 9 of 24\n",
      "    ğŸ“„ Scraping page 10 of 24\n",
      "    ğŸ“„ Scraping page 11 of 24\n",
      "    ğŸ“„ Scraping page 12 of 24\n",
      "    ğŸ“„ Scraping page 13 of 24\n",
      "    ğŸ“„ Scraping page 14 of 24\n",
      "    ğŸ“„ Scraping page 15 of 24\n",
      "    ğŸ“„ Scraping page 16 of 24\n",
      "    ğŸ“„ Scraping page 17 of 24\n",
      "    ğŸ“„ Scraping page 18 of 24\n",
      "    ğŸ“„ Scraping page 19 of 24\n",
      "    ğŸ“„ Scraping page 20 of 24\n",
      "    ğŸ“„ Scraping page 21 of 24\n",
      "    ğŸ“„ Scraping page 22 of 24\n",
      "    ğŸ“„ Scraping page 23 of 24\n",
      "    ğŸ“„ Scraping page 24 of 24\n",
      "  ğŸ”¤ Scraping letter: b (19 pages, 455 entries)\n",
      "    ğŸ“„ Scraping page 1 of 19\n",
      "    ğŸ“„ Scraping page 2 of 19\n",
      "    ğŸ“„ Scraping page 3 of 19\n",
      "    ğŸ“„ Scraping page 4 of 19\n",
      "    ğŸ“„ Scraping page 5 of 19\n",
      "    ğŸ“„ Scraping page 6 of 19\n",
      "    ğŸ“„ Scraping page 7 of 19\n",
      "    ğŸ“„ Scraping page 8 of 19\n",
      "    ğŸ“„ Scraping page 9 of 19\n",
      "    ğŸ“„ Scraping page 10 of 19\n",
      "    ğŸ“„ Scraping page 11 of 19\n",
      "    ğŸ“„ Scraping page 12 of 19\n",
      "    ğŸ“„ Scraping page 13 of 19\n",
      "    ğŸ“„ Scraping page 14 of 19\n",
      "    ğŸ“„ Scraping page 15 of 19\n",
      "    ğŸ“„ Scraping page 16 of 19\n",
      "    ğŸ“„ Scraping page 17 of 19\n",
      "    ğŸ“„ Scraping page 18 of 19\n",
      "    ğŸ“„ Scraping page 19 of 19\n",
      "  ğŸ”¤ Scraping letter: c (38 pages, 944 entries)\n",
      "    ğŸ“„ Scraping page 1 of 38\n",
      "    ğŸ“„ Scraping page 2 of 38\n",
      "    ğŸ“„ Scraping page 3 of 38\n",
      "    ğŸ“„ Scraping page 4 of 38\n",
      "    ğŸ“„ Scraping page 5 of 38\n",
      "    ğŸ“„ Scraping page 6 of 38\n",
      "    ğŸ“„ Scraping page 7 of 38\n",
      "    ğŸ“„ Scraping page 8 of 38\n",
      "    ğŸ“„ Scraping page 9 of 38\n",
      "    ğŸ“„ Scraping page 10 of 38\n",
      "    ğŸ“„ Scraping page 11 of 38\n",
      "    ğŸ“„ Scraping page 12 of 38\n",
      "    ğŸ“„ Scraping page 13 of 38\n",
      "    ğŸ“„ Scraping page 14 of 38\n",
      "    ğŸ“„ Scraping page 15 of 38\n",
      "    ğŸ“„ Scraping page 16 of 38\n",
      "    ğŸ“„ Scraping page 17 of 38\n",
      "    ğŸ“„ Scraping page 18 of 38\n",
      "    ğŸ“„ Scraping page 19 of 38\n",
      "    ğŸ“„ Scraping page 20 of 38\n",
      "    ğŸ“„ Scraping page 21 of 38\n",
      "    ğŸ“„ Scraping page 22 of 38\n",
      "    ğŸ“„ Scraping page 23 of 38\n",
      "    ğŸ“„ Scraping page 24 of 38\n",
      "    ğŸ“„ Scraping page 25 of 38\n",
      "    ğŸ“„ Scraping page 26 of 38\n",
      "    ğŸ“„ Scraping page 27 of 38\n",
      "    ğŸ“„ Scraping page 28 of 38\n",
      "    ğŸ“„ Scraping page 29 of 38\n",
      "    ğŸ“„ Scraping page 30 of 38\n",
      "    ğŸ“„ Scraping page 31 of 38\n",
      "    ğŸ“„ Scraping page 32 of 38\n",
      "    ğŸ“„ Scraping page 33 of 38\n",
      "    ğŸ“„ Scraping page 34 of 38\n",
      "    ğŸ“„ Scraping page 35 of 38\n",
      "    ğŸ“„ Scraping page 36 of 38\n",
      "    ğŸ“„ Scraping page 37 of 38\n",
      "    ğŸ“„ Scraping page 38 of 38\n",
      "  ğŸ”¤ Scraping letter: d (21 pages, 519 entries)\n",
      "    ğŸ“„ Scraping page 1 of 21\n",
      "    ğŸ“„ Scraping page 2 of 21\n",
      "    ğŸ“„ Scraping page 3 of 21\n",
      "    ğŸ“„ Scraping page 4 of 21\n",
      "    ğŸ“„ Scraping page 5 of 21\n",
      "    ğŸ“„ Scraping page 6 of 21\n",
      "    ğŸ“„ Scraping page 7 of 21\n",
      "    ğŸ“„ Scraping page 8 of 21\n",
      "    ğŸ“„ Scraping page 9 of 21\n",
      "    ğŸ“„ Scraping page 10 of 21\n",
      "    ğŸ“„ Scraping page 11 of 21\n",
      "    ğŸ“„ Scraping page 12 of 21\n",
      "    ğŸ“„ Scraping page 13 of 21\n",
      "    ğŸ“„ Scraping page 14 of 21\n",
      "    ğŸ“„ Scraping page 15 of 21\n",
      "    ğŸ“„ Scraping page 16 of 21\n",
      "    ğŸ“„ Scraping page 17 of 21\n",
      "    ğŸ“„ Scraping page 18 of 21\n",
      "    ğŸ“„ Scraping page 19 of 21\n",
      "    ğŸ“„ Scraping page 20 of 21\n",
      "    ğŸ“„ Scraping page 21 of 21\n",
      "  ğŸ”¤ Scraping letter: e (22 pages, 545 entries)\n",
      "    ğŸ“„ Scraping page 1 of 22\n",
      "    ğŸ“„ Scraping page 2 of 22\n",
      "    ğŸ“„ Scraping page 3 of 22\n",
      "    ğŸ“„ Scraping page 4 of 22\n",
      "    ğŸ“„ Scraping page 5 of 22\n",
      "    ğŸ“„ Scraping page 6 of 22\n",
      "    ğŸ“„ Scraping page 7 of 22\n",
      "    ğŸ“„ Scraping page 8 of 22\n",
      "    ğŸ“„ Scraping page 9 of 22\n",
      "    ğŸ“„ Scraping page 10 of 22\n",
      "    ğŸ“„ Scraping page 11 of 22\n",
      "    ğŸ“„ Scraping page 12 of 22\n",
      "    ğŸ“„ Scraping page 13 of 22\n",
      "    ğŸ“„ Scraping page 14 of 22\n",
      "    ğŸ“„ Scraping page 15 of 22\n",
      "    ğŸ“„ Scraping page 16 of 22\n",
      "    ğŸ“„ Scraping page 17 of 22\n",
      "    ğŸ“„ Scraping page 18 of 22\n",
      "    ğŸ“„ Scraping page 19 of 22\n",
      "    ğŸ“„ Scraping page 20 of 22\n",
      "    ğŸ“„ Scraping page 21 of 22\n",
      "    ğŸ“„ Scraping page 22 of 22\n",
      "  ğŸ”¤ Scraping letter: f (15 pages, 373 entries)\n",
      "    ğŸ“„ Scraping page 1 of 15\n",
      "    ğŸ“„ Scraping page 2 of 15\n",
      "    ğŸ“„ Scraping page 3 of 15\n",
      "    ğŸ“„ Scraping page 4 of 15\n",
      "    ğŸ“„ Scraping page 5 of 15\n",
      "    ğŸ“„ Scraping page 6 of 15\n",
      "    ğŸ“„ Scraping page 7 of 15\n",
      "    ğŸ“„ Scraping page 8 of 15\n",
      "    ğŸ“„ Scraping page 9 of 15\n",
      "    ğŸ“„ Scraping page 10 of 15\n",
      "    ğŸ“„ Scraping page 11 of 15\n",
      "    ğŸ“„ Scraping page 12 of 15\n",
      "    ğŸ“„ Scraping page 13 of 15\n",
      "    ğŸ“„ Scraping page 14 of 15\n",
      "    ğŸ“„ Scraping page 15 of 15\n",
      "  ğŸ”¤ Scraping letter: g (10 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 10\n",
      "    ğŸ“„ Scraping page 2 of 10\n",
      "    ğŸ“„ Scraping page 3 of 10\n",
      "    ğŸ“„ Scraping page 4 of 10\n",
      "    ğŸ“„ Scraping page 5 of 10\n",
      "    ğŸ“„ Scraping page 6 of 10\n",
      "    ğŸ“„ Scraping page 7 of 10\n",
      "    ğŸ“„ Scraping page 8 of 10\n",
      "    ğŸ“„ Scraping page 9 of 10\n",
      "    ğŸ“„ Scraping page 10 of 10\n",
      "  ğŸ”¤ Scraping letter: h (7 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 7\n",
      "    ğŸ“„ Scraping page 2 of 7\n",
      "    ğŸ“„ Scraping page 3 of 7\n",
      "    ğŸ“„ Scraping page 4 of 7\n",
      "    ğŸ“„ Scraping page 5 of 7\n",
      "    ğŸ“„ Scraping page 6 of 7\n",
      "    ğŸ“„ Scraping page 7 of 7\n",
      "  ğŸ”¤ Scraping letter: i (9 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 9\n",
      "    ğŸ“„ Scraping page 2 of 9\n",
      "    ğŸ“„ Scraping page 3 of 9\n",
      "    ğŸ“„ Scraping page 4 of 9\n",
      "    ğŸ“„ Scraping page 5 of 9\n",
      "    ğŸ“„ Scraping page 6 of 9\n",
      "    ğŸ“„ Scraping page 7 of 9\n",
      "    ğŸ“„ Scraping page 8 of 9\n",
      "    ğŸ“„ Scraping page 9 of 9\n",
      "  ğŸ”¤ Scraping letter: j (5 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 5\n",
      "    ğŸ“„ Scraping page 2 of 5\n",
      "    ğŸ“„ Scraping page 3 of 5\n",
      "    ğŸ“„ Scraping page 4 of 5\n",
      "    ğŸ“„ Scraping page 5 of 5\n",
      "  ğŸ”¤ Scraping letter: k (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: l (9 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 9\n",
      "    ğŸ“„ Scraping page 2 of 9\n",
      "    ğŸ“„ Scraping page 3 of 9\n",
      "    ğŸ“„ Scraping page 4 of 9\n",
      "    ğŸ“„ Scraping page 5 of 9\n",
      "    ğŸ“„ Scraping page 6 of 9\n",
      "    ğŸ“„ Scraping page 7 of 9\n",
      "    ğŸ“„ Scraping page 8 of 9\n",
      "    ğŸ“„ Scraping page 9 of 9\n",
      "  ğŸ”¤ Scraping letter: m (23 pages, 551 entries)\n",
      "    ğŸ“„ Scraping page 1 of 23\n",
      "    ğŸ“„ Scraping page 2 of 23\n",
      "    ğŸ“„ Scraping page 3 of 23\n",
      "    ğŸ“„ Scraping page 4 of 23\n",
      "    ğŸ“„ Scraping page 5 of 23\n",
      "    ğŸ“„ Scraping page 6 of 23\n",
      "    ğŸ“„ Scraping page 7 of 23\n",
      "    ğŸ“„ Scraping page 8 of 23\n",
      "    ğŸ“„ Scraping page 9 of 23\n",
      "    ğŸ“„ Scraping page 10 of 23\n",
      "    ğŸ“„ Scraping page 11 of 23\n",
      "    ğŸ“„ Scraping page 12 of 23\n",
      "    ğŸ“„ Scraping page 13 of 23\n",
      "    ğŸ“„ Scraping page 14 of 23\n",
      "    ğŸ“„ Scraping page 15 of 23\n",
      "    ğŸ“„ Scraping page 16 of 23\n",
      "    ğŸ“„ Scraping page 17 of 23\n",
      "    ğŸ“„ Scraping page 18 of 23\n",
      "    ğŸ“„ Scraping page 19 of 23\n",
      "    ğŸ“„ Scraping page 20 of 23\n",
      "    ğŸ“„ Scraping page 21 of 23\n",
      "    ğŸ“„ Scraping page 22 of 23\n",
      "    ğŸ“„ Scraping page 23 of 23\n",
      "  ğŸ”¤ Scraping letter: n (6 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 6\n",
      "    ğŸ“„ Scraping page 2 of 6\n",
      "    ğŸ“„ Scraping page 3 of 6\n",
      "    ğŸ“„ Scraping page 4 of 6\n",
      "    ğŸ“„ Scraping page 5 of 6\n",
      "    ğŸ“„ Scraping page 6 of 6\n",
      "  ğŸ”¤ Scraping letter: o (6 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 6\n",
      "    ğŸ“„ Scraping page 2 of 6\n",
      "    ğŸ“„ Scraping page 3 of 6\n",
      "    ğŸ“„ Scraping page 4 of 6\n",
      "    ğŸ“„ Scraping page 5 of 6\n",
      "    ğŸ“„ Scraping page 6 of 6\n",
      "  ğŸ”¤ Scraping letter: p (31 pages, 752 entries)\n",
      "    ğŸ“„ Scraping page 1 of 31\n",
      "    ğŸ“„ Scraping page 2 of 31\n",
      "    ğŸ“„ Scraping page 3 of 31\n",
      "    ğŸ“„ Scraping page 4 of 31\n",
      "    ğŸ“„ Scraping page 5 of 31\n",
      "    ğŸ“„ Scraping page 6 of 31\n",
      "    ğŸ“„ Scraping page 7 of 31\n",
      "    ğŸ“„ Scraping page 8 of 31\n",
      "    ğŸ“„ Scraping page 9 of 31\n",
      "    ğŸ“„ Scraping page 10 of 31\n",
      "    ğŸ“„ Scraping page 11 of 31\n",
      "    ğŸ“„ Scraping page 12 of 31\n",
      "    ğŸ“„ Scraping page 13 of 31\n",
      "    ğŸ“„ Scraping page 14 of 31\n",
      "    ğŸ“„ Scraping page 15 of 31\n",
      "    ğŸ“„ Scraping page 16 of 31\n",
      "    ğŸ“„ Scraping page 17 of 31\n",
      "    ğŸ“„ Scraping page 18 of 31\n",
      "    ğŸ“„ Scraping page 19 of 31\n",
      "    ğŸ“„ Scraping page 20 of 31\n",
      "    ğŸ“„ Scraping page 21 of 31\n",
      "    ğŸ“„ Scraping page 22 of 31\n",
      "    ğŸ“„ Scraping page 23 of 31\n",
      "    ğŸ“„ Scraping page 24 of 31\n",
      "    ğŸ“„ Scraping page 25 of 31\n",
      "    ğŸ“„ Scraping page 26 of 31\n",
      "    ğŸ“„ Scraping page 27 of 31\n",
      "    ğŸ“„ Scraping page 28 of 31\n",
      "    ğŸ“„ Scraping page 29 of 31\n",
      "    ğŸ“„ Scraping page 30 of 31\n",
      "    ğŸ“„ Scraping page 31 of 31\n",
      "  ğŸ”¤ Scraping letter: q (2 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 2\n",
      "    ğŸ“„ Scraping page 2 of 2\n",
      "  ğŸ”¤ Scraping letter: r (17 pages, 406 entries)\n",
      "    ğŸ“„ Scraping page 1 of 17\n",
      "    ğŸ“„ Scraping page 2 of 17\n",
      "    ğŸ“„ Scraping page 3 of 17\n",
      "    ğŸ“„ Scraping page 4 of 17\n",
      "    ğŸ“„ Scraping page 5 of 17\n",
      "    ğŸ“„ Scraping page 6 of 17\n",
      "    ğŸ“„ Scraping page 7 of 17\n",
      "    ğŸ“„ Scraping page 8 of 17\n",
      "    ğŸ“„ Scraping page 9 of 17\n",
      "    ğŸ“„ Scraping page 10 of 17\n",
      "    ğŸ“„ Scraping page 11 of 17\n",
      "    ğŸ“„ Scraping page 12 of 17\n",
      "    ğŸ“„ Scraping page 13 of 17\n",
      "    ğŸ“„ Scraping page 14 of 17\n",
      "    ğŸ“„ Scraping page 15 of 17\n",
      "    ğŸ“„ Scraping page 16 of 17\n",
      "    ğŸ“„ Scraping page 17 of 17\n",
      "  ğŸ”¤ Scraping letter: s (20 pages, 495 entries)\n",
      "    ğŸ“„ Scraping page 1 of 20\n",
      "    ğŸ“„ Scraping page 2 of 20\n",
      "    ğŸ“„ Scraping page 3 of 20\n",
      "    ğŸ“„ Scraping page 4 of 20\n",
      "    ğŸ“„ Scraping page 5 of 20\n",
      "    ğŸ“„ Scraping page 6 of 20\n",
      "    ğŸ“„ Scraping page 7 of 20\n",
      "    ğŸ“„ Scraping page 8 of 20\n",
      "    ğŸ“„ Scraping page 9 of 20\n",
      "    ğŸ“„ Scraping page 10 of 20\n",
      "    ğŸ“„ Scraping page 11 of 20\n",
      "    ğŸ“„ Scraping page 12 of 20\n",
      "    ğŸ“„ Scraping page 13 of 20\n",
      "    ğŸ“„ Scraping page 14 of 20\n",
      "    ğŸ“„ Scraping page 15 of 20\n",
      "    ğŸ“„ Scraping page 16 of 20\n",
      "    ğŸ“„ Scraping page 17 of 20\n",
      "    ğŸ“„ Scraping page 18 of 20\n",
      "    ğŸ“„ Scraping page 19 of 20\n",
      "    ğŸ“„ Scraping page 20 of 20\n",
      "  ğŸ”¤ Scraping letter: t (18 pages, 450 entries)\n",
      "    ğŸ“„ Scraping page 1 of 18\n",
      "    ğŸ“„ Scraping page 2 of 18\n",
      "    ğŸ“„ Scraping page 3 of 18\n",
      "    ğŸ“„ Scraping page 4 of 18\n",
      "    ğŸ“„ Scraping page 5 of 18\n",
      "    ğŸ“„ Scraping page 6 of 18\n",
      "    ğŸ“„ Scraping page 7 of 18\n",
      "    ğŸ“„ Scraping page 8 of 18\n",
      "    ğŸ“„ Scraping page 9 of 18\n",
      "    ğŸ“„ Scraping page 10 of 18\n",
      "    ğŸ“„ Scraping page 11 of 18\n",
      "    ğŸ“„ Scraping page 12 of 18\n",
      "    ğŸ“„ Scraping page 13 of 18\n",
      "    ğŸ“„ Scraping page 14 of 18\n",
      "    ğŸ“„ Scraping page 15 of 18\n",
      "    ğŸ“„ Scraping page 16 of 18\n",
      "    ğŸ“„ Scraping page 17 of 18\n",
      "    ğŸ“„ Scraping page 18 of 18\n",
      "  ğŸ”¤ Scraping letter: u (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: v (9 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 9\n",
      "    ğŸ“„ Scraping page 2 of 9\n",
      "    ğŸ“„ Scraping page 3 of 9\n",
      "    ğŸ“„ Scraping page 4 of 9\n",
      "    ğŸ“„ Scraping page 5 of 9\n",
      "    ğŸ“„ Scraping page 6 of 9\n",
      "    ğŸ“„ Scraping page 7 of 9\n",
      "    ğŸ“„ Scraping page 8 of 9\n",
      "    ğŸ“„ Scraping page 9 of 9\n",
      "  ğŸ”¤ Scraping letter: w (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: x (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: y (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: z (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "ğŸ“– Scraping category: English\n",
      "  ğŸ”¤ Scraping letter: a (16 pages, 382 entries)\n",
      "    ğŸ“„ Scraping page 1 of 16\n",
      "    ğŸ“„ Scraping page 2 of 16\n",
      "    ğŸ“„ Scraping page 3 of 16\n",
      "    ğŸ“„ Scraping page 4 of 16\n",
      "    ğŸ“„ Scraping page 5 of 16\n",
      "    ğŸ“„ Scraping page 6 of 16\n",
      "    ğŸ“„ Scraping page 7 of 16\n",
      "    ğŸ“„ Scraping page 8 of 16\n",
      "    ğŸ“„ Scraping page 9 of 16\n",
      "    ğŸ“„ Scraping page 10 of 16\n",
      "    ğŸ“„ Scraping page 11 of 16\n",
      "    ğŸ“„ Scraping page 12 of 16\n",
      "    ğŸ“„ Scraping page 13 of 16\n",
      "    ğŸ“„ Scraping page 14 of 16\n",
      "    ğŸ“„ Scraping page 15 of 16\n",
      "    ğŸ“„ Scraping page 16 of 16\n",
      "  ğŸ”¤ Scraping letter: b (23 pages, 551 entries)\n",
      "    ğŸ“„ Scraping page 1 of 23\n",
      "    ğŸ“„ Scraping page 2 of 23\n",
      "    ğŸ“„ Scraping page 3 of 23\n",
      "    ğŸ“„ Scraping page 4 of 23\n",
      "    ğŸ“„ Scraping page 5 of 23\n",
      "    ğŸ“„ Scraping page 6 of 23\n",
      "    ğŸ“„ Scraping page 7 of 23\n",
      "    ğŸ“„ Scraping page 8 of 23\n",
      "    ğŸ“„ Scraping page 9 of 23\n",
      "    ğŸ“„ Scraping page 10 of 23\n",
      "    ğŸ“„ Scraping page 11 of 23\n",
      "    ğŸ“„ Scraping page 12 of 23\n",
      "    ğŸ“„ Scraping page 13 of 23\n",
      "    ğŸ“„ Scraping page 14 of 23\n",
      "    ğŸ“„ Scraping page 15 of 23\n",
      "    ğŸ“„ Scraping page 16 of 23\n",
      "    ğŸ“„ Scraping page 17 of 23\n",
      "    ğŸ“„ Scraping page 18 of 23\n",
      "    ğŸ“„ Scraping page 19 of 23\n",
      "    ğŸ“„ Scraping page 20 of 23\n",
      "    ğŸ“„ Scraping page 21 of 23\n",
      "    ğŸ“„ Scraping page 22 of 23\n",
      "    ğŸ“„ Scraping page 23 of 23\n",
      "  ğŸ”¤ Scraping letter: c (33 pages, 817 entries)\n",
      "    ğŸ“„ Scraping page 1 of 33\n",
      "    ğŸ“„ Scraping page 2 of 33\n",
      "    ğŸ“„ Scraping page 3 of 33\n",
      "    ğŸ“„ Scraping page 4 of 33\n",
      "    ğŸ“„ Scraping page 5 of 33\n",
      "    ğŸ“„ Scraping page 6 of 33\n",
      "    ğŸ“„ Scraping page 7 of 33\n",
      "    ğŸ“„ Scraping page 8 of 33\n",
      "    ğŸ“„ Scraping page 9 of 33\n",
      "    ğŸ“„ Scraping page 10 of 33\n",
      "    ğŸ“„ Scraping page 11 of 33\n",
      "    ğŸ“„ Scraping page 12 of 33\n",
      "    ğŸ“„ Scraping page 13 of 33\n",
      "    ğŸ“„ Scraping page 14 of 33\n",
      "    ğŸ“„ Scraping page 15 of 33\n",
      "    ğŸ“„ Scraping page 16 of 33\n",
      "    ğŸ“„ Scraping page 17 of 33\n",
      "    ğŸ“„ Scraping page 18 of 33\n",
      "    ğŸ“„ Scraping page 19 of 33\n",
      "    ğŸ“„ Scraping page 20 of 33\n",
      "    ğŸ“„ Scraping page 21 of 33\n",
      "    ğŸ“„ Scraping page 22 of 33\n",
      "    ğŸ“„ Scraping page 23 of 33\n",
      "    ğŸ“„ Scraping page 24 of 33\n",
      "    ğŸ“„ Scraping page 25 of 33\n",
      "    ğŸ“„ Scraping page 26 of 33\n",
      "    ğŸ“„ Scraping page 27 of 33\n",
      "    ğŸ“„ Scraping page 28 of 33\n",
      "    ğŸ“„ Scraping page 29 of 33\n",
      "    ğŸ“„ Scraping page 30 of 33\n",
      "    ğŸ“„ Scraping page 31 of 33\n",
      "    ğŸ“„ Scraping page 32 of 33\n",
      "    ğŸ“„ Scraping page 33 of 33\n",
      "  ğŸ”¤ Scraping letter: d (20 pages, 480 entries)\n",
      "    ğŸ“„ Scraping page 1 of 20\n",
      "    ğŸ“„ Scraping page 2 of 20\n",
      "    ğŸ“„ Scraping page 3 of 20\n",
      "    ğŸ“„ Scraping page 4 of 20\n",
      "    ğŸ“„ Scraping page 5 of 20\n",
      "    ğŸ“„ Scraping page 6 of 20\n",
      "    ğŸ“„ Scraping page 7 of 20\n",
      "    ğŸ“„ Scraping page 8 of 20\n",
      "    ğŸ“„ Scraping page 9 of 20\n",
      "    ğŸ“„ Scraping page 10 of 20\n",
      "    ğŸ“„ Scraping page 11 of 20\n",
      "    ğŸ“„ Scraping page 12 of 20\n",
      "    ğŸ“„ Scraping page 13 of 20\n",
      "    ğŸ“„ Scraping page 14 of 20\n",
      "    ğŸ“„ Scraping page 15 of 20\n",
      "    ğŸ“„ Scraping page 16 of 20\n",
      "    ğŸ“„ Scraping page 17 of 20\n",
      "    ğŸ“„ Scraping page 18 of 20\n",
      "    ğŸ“„ Scraping page 19 of 20\n",
      "    ğŸ“„ Scraping page 20 of 20\n",
      "  ğŸ”¤ Scraping letter: e (11 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 11\n",
      "    ğŸ“„ Scraping page 2 of 11\n",
      "    ğŸ“„ Scraping page 3 of 11\n",
      "    ğŸ“„ Scraping page 4 of 11\n",
      "    ğŸ“„ Scraping page 5 of 11\n",
      "    ğŸ“„ Scraping page 6 of 11\n",
      "    ğŸ“„ Scraping page 7 of 11\n",
      "    ğŸ“„ Scraping page 8 of 11\n",
      "    ğŸ“„ Scraping page 9 of 11\n",
      "    ğŸ“„ Scraping page 10 of 11\n",
      "    ğŸ“„ Scraping page 11 of 11\n",
      "  ğŸ”¤ Scraping letter: f (18 pages, 435 entries)\n",
      "    ğŸ“„ Scraping page 1 of 18\n",
      "    ğŸ“„ Scraping page 2 of 18\n",
      "    ğŸ“„ Scraping page 3 of 18\n",
      "    ğŸ“„ Scraping page 4 of 18\n",
      "    ğŸ“„ Scraping page 5 of 18\n",
      "    ğŸ“„ Scraping page 6 of 18\n",
      "    ğŸ“„ Scraping page 7 of 18\n",
      "    ğŸ“„ Scraping page 8 of 18\n",
      "    ğŸ“„ Scraping page 9 of 18\n",
      "    ğŸ“„ Scraping page 10 of 18\n",
      "    ğŸ“„ Scraping page 11 of 18\n",
      "    ğŸ“„ Scraping page 12 of 18\n",
      "    ğŸ“„ Scraping page 13 of 18\n",
      "    ğŸ“„ Scraping page 14 of 18\n",
      "    ğŸ“„ Scraping page 15 of 18\n",
      "    ğŸ“„ Scraping page 16 of 18\n",
      "    ğŸ“„ Scraping page 17 of 18\n",
      "    ğŸ“„ Scraping page 18 of 18\n",
      "  ğŸ”¤ Scraping letter: g (13 pages, 304 entries)\n",
      "    ğŸ“„ Scraping page 1 of 13\n",
      "    ğŸ“„ Scraping page 2 of 13\n",
      "    ğŸ“„ Scraping page 3 of 13\n",
      "    ğŸ“„ Scraping page 4 of 13\n",
      "    ğŸ“„ Scraping page 5 of 13\n",
      "    ğŸ“„ Scraping page 6 of 13\n",
      "    ğŸ“„ Scraping page 7 of 13\n",
      "    ğŸ“„ Scraping page 8 of 13\n",
      "    ğŸ“„ Scraping page 9 of 13\n",
      "    ğŸ“„ Scraping page 10 of 13\n",
      "    ğŸ“„ Scraping page 11 of 13\n",
      "    ğŸ“„ Scraping page 12 of 13\n",
      "    ğŸ“„ Scraping page 13 of 13\n",
      "  ğŸ”¤ Scraping letter: h (14 pages, 341 entries)\n",
      "    ğŸ“„ Scraping page 1 of 14\n",
      "    ğŸ“„ Scraping page 2 of 14\n",
      "    ğŸ“„ Scraping page 3 of 14\n",
      "    ğŸ“„ Scraping page 4 of 14\n",
      "    ğŸ“„ Scraping page 5 of 14\n",
      "    ğŸ“„ Scraping page 6 of 14\n",
      "    ğŸ“„ Scraping page 7 of 14\n",
      "    ğŸ“„ Scraping page 8 of 14\n",
      "    ğŸ“„ Scraping page 9 of 14\n",
      "    ğŸ“„ Scraping page 10 of 14\n",
      "    ğŸ“„ Scraping page 11 of 14\n",
      "    ğŸ“„ Scraping page 12 of 14\n",
      "    ğŸ“„ Scraping page 13 of 14\n",
      "    ğŸ“„ Scraping page 14 of 14\n",
      "  ğŸ”¤ Scraping letter: i (9 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 9\n",
      "    ğŸ“„ Scraping page 2 of 9\n",
      "    ğŸ“„ Scraping page 3 of 9\n",
      "    ğŸ“„ Scraping page 4 of 9\n",
      "    ğŸ“„ Scraping page 5 of 9\n",
      "    ğŸ“„ Scraping page 6 of 9\n",
      "    ğŸ“„ Scraping page 7 of 9\n",
      "    ğŸ“„ Scraping page 8 of 9\n",
      "    ğŸ“„ Scraping page 9 of 9\n",
      "  ğŸ”¤ Scraping letter: j (3 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 3\n",
      "    ğŸ“„ Scraping page 2 of 3\n",
      "    ğŸ“„ Scraping page 3 of 3\n",
      "  ğŸ”¤ Scraping letter: k (4 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 4\n",
      "    ğŸ“„ Scraping page 2 of 4\n",
      "    ğŸ“„ Scraping page 3 of 4\n",
      "    ğŸ“„ Scraping page 4 of 4\n",
      "  ğŸ”¤ Scraping letter: l (12 pages, 300 entries)\n",
      "    ğŸ“„ Scraping page 1 of 12\n",
      "    ğŸ“„ Scraping page 2 of 12\n",
      "    ğŸ“„ Scraping page 3 of 12\n",
      "    ğŸ“„ Scraping page 4 of 12\n",
      "    ğŸ“„ Scraping page 5 of 12\n",
      "    ğŸ“„ Scraping page 6 of 12\n",
      "    ğŸ“„ Scraping page 7 of 12\n",
      "    ğŸ“„ Scraping page 8 of 12\n",
      "    ğŸ“„ Scraping page 9 of 12\n",
      "    ğŸ“„ Scraping page 10 of 12\n",
      "    ğŸ“„ Scraping page 11 of 12\n",
      "    ğŸ“„ Scraping page 12 of 12\n",
      "  ğŸ”¤ Scraping letter: m (18 pages, 441 entries)\n",
      "    ğŸ“„ Scraping page 1 of 18\n",
      "    ğŸ“„ Scraping page 2 of 18\n",
      "    ğŸ“„ Scraping page 3 of 18\n",
      "    ğŸ“„ Scraping page 4 of 18\n",
      "    ğŸ“„ Scraping page 5 of 18\n",
      "    ğŸ“„ Scraping page 6 of 18\n",
      "    ğŸ“„ Scraping page 7 of 18\n",
      "    ğŸ“„ Scraping page 8 of 18\n",
      "    ğŸ“„ Scraping page 9 of 18\n",
      "    ğŸ“„ Scraping page 10 of 18\n",
      "    ğŸ“„ Scraping page 11 of 18\n",
      "    ğŸ“„ Scraping page 12 of 18\n",
      "    ğŸ“„ Scraping page 13 of 18\n",
      "    ğŸ“„ Scraping page 14 of 18\n",
      "    ğŸ“„ Scraping page 15 of 18\n",
      "    ğŸ“„ Scraping page 16 of 18\n",
      "    ğŸ“„ Scraping page 17 of 18\n",
      "    ğŸ“„ Scraping page 18 of 18\n",
      "  ğŸ”¤ Scraping letter: n (6 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 6\n",
      "    ğŸ“„ Scraping page 2 of 6\n",
      "    ğŸ“„ Scraping page 3 of 6\n",
      "    ğŸ“„ Scraping page 4 of 6\n",
      "    ğŸ“„ Scraping page 5 of 6\n",
      "    ğŸ“„ Scraping page 6 of 6\n",
      "  ğŸ”¤ Scraping letter: o (6 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 6\n",
      "    ğŸ“„ Scraping page 2 of 6\n",
      "    ğŸ“„ Scraping page 3 of 6\n",
      "    ğŸ“„ Scraping page 4 of 6\n",
      "    ğŸ“„ Scraping page 5 of 6\n",
      "    ğŸ“„ Scraping page 6 of 6\n",
      "  ğŸ”¤ Scraping letter: p (23 pages, 566 entries)\n",
      "    ğŸ“„ Scraping page 1 of 23\n",
      "    ğŸ“„ Scraping page 2 of 23\n",
      "    ğŸ“„ Scraping page 3 of 23\n",
      "    ğŸ“„ Scraping page 4 of 23\n",
      "    ğŸ“„ Scraping page 5 of 23\n",
      "    ğŸ“„ Scraping page 6 of 23\n",
      "    ğŸ“„ Scraping page 7 of 23\n",
      "    ğŸ“„ Scraping page 8 of 23\n",
      "    ğŸ“„ Scraping page 9 of 23\n",
      "    ğŸ“„ Scraping page 10 of 23\n",
      "    ğŸ“„ Scraping page 11 of 23\n",
      "    ğŸ“„ Scraping page 12 of 23\n",
      "    ğŸ“„ Scraping page 13 of 23\n",
      "    ğŸ“„ Scraping page 14 of 23\n",
      "    ğŸ“„ Scraping page 15 of 23\n",
      "    ğŸ“„ Scraping page 16 of 23\n",
      "    ğŸ“„ Scraping page 17 of 23\n",
      "    ğŸ“„ Scraping page 18 of 23\n",
      "    ğŸ“„ Scraping page 19 of 23\n",
      "    ğŸ“„ Scraping page 20 of 23\n",
      "    ğŸ“„ Scraping page 21 of 23\n",
      "    ğŸ“„ Scraping page 22 of 23\n",
      "    ğŸ“„ Scraping page 23 of 23\n",
      "  ğŸ”¤ Scraping letter: q (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: r (14 pages, 338 entries)\n",
      "    ğŸ“„ Scraping page 1 of 14\n",
      "    ğŸ“„ Scraping page 2 of 14\n",
      "    ğŸ“„ Scraping page 3 of 14\n",
      "    ğŸ“„ Scraping page 4 of 14\n",
      "    ğŸ“„ Scraping page 5 of 14\n",
      "    ğŸ“„ Scraping page 6 of 14\n",
      "    ğŸ“„ Scraping page 7 of 14\n",
      "    ğŸ“„ Scraping page 8 of 14\n",
      "    ğŸ“„ Scraping page 9 of 14\n",
      "    ğŸ“„ Scraping page 10 of 14\n",
      "    ğŸ“„ Scraping page 11 of 14\n",
      "    ğŸ“„ Scraping page 12 of 14\n",
      "    ğŸ“„ Scraping page 13 of 14\n",
      "    ğŸ“„ Scraping page 14 of 14\n",
      "  ğŸ”¤ Scraping letter: s (43 pages, 1066 entries)\n",
      "    ğŸ“„ Scraping page 1 of 43\n",
      "    ğŸ“„ Scraping page 2 of 43\n",
      "    ğŸ“„ Scraping page 3 of 43\n",
      "    ğŸ“„ Scraping page 4 of 43\n",
      "    ğŸ“„ Scraping page 5 of 43\n",
      "    ğŸ“„ Scraping page 6 of 43\n",
      "    ğŸ“„ Scraping page 7 of 43\n",
      "    ğŸ“„ Scraping page 8 of 43\n",
      "    ğŸ“„ Scraping page 9 of 43\n",
      "    ğŸ“„ Scraping page 10 of 43\n",
      "    ğŸ“„ Scraping page 11 of 43\n",
      "    ğŸ“„ Scraping page 12 of 43\n",
      "    ğŸ“„ Scraping page 13 of 43\n",
      "    ğŸ“„ Scraping page 14 of 43\n",
      "    ğŸ“„ Scraping page 15 of 43\n",
      "    ğŸ“„ Scraping page 16 of 43\n",
      "    ğŸ“„ Scraping page 17 of 43\n",
      "    ğŸ“„ Scraping page 18 of 43\n",
      "    ğŸ“„ Scraping page 19 of 43\n",
      "    ğŸ“„ Scraping page 20 of 43\n",
      "    ğŸ“„ Scraping page 21 of 43\n",
      "    ğŸ“„ Scraping page 22 of 43\n",
      "    ğŸ“„ Scraping page 23 of 43\n",
      "    ğŸ“„ Scraping page 24 of 43\n",
      "    ğŸ“„ Scraping page 25 of 43\n",
      "    ğŸ“„ Scraping page 26 of 43\n",
      "    ğŸ“„ Scraping page 27 of 43\n",
      "    ğŸ“„ Scraping page 28 of 43\n",
      "    ğŸ“„ Scraping page 29 of 43\n",
      "    ğŸ“„ Scraping page 30 of 43\n",
      "    ğŸ“„ Scraping page 31 of 43\n",
      "    ğŸ“„ Scraping page 32 of 43\n",
      "    ğŸ“„ Scraping page 33 of 43\n",
      "    ğŸ“„ Scraping page 34 of 43\n",
      "    ğŸ“„ Scraping page 35 of 43\n",
      "    ğŸ“„ Scraping page 36 of 43\n",
      "    ğŸ“„ Scraping page 37 of 43\n",
      "    ğŸ“„ Scraping page 38 of 43\n",
      "    ğŸ“„ Scraping page 39 of 43\n",
      "    ğŸ“„ Scraping page 40 of 43\n",
      "    ğŸ“„ Scraping page 41 of 43\n",
      "    ğŸ“„ Scraping page 42 of 43\n",
      "    ğŸ“„ Scraping page 43 of 43\n",
      "  ğŸ”¤ Scraping letter: t (20 pages, 488 entries)\n",
      "    ğŸ“„ Scraping page 1 of 20\n",
      "    ğŸ“„ Scraping page 2 of 20\n",
      "    ğŸ“„ Scraping page 3 of 20\n",
      "    ğŸ“„ Scraping page 4 of 20\n",
      "    ğŸ“„ Scraping page 5 of 20\n",
      "    ğŸ“„ Scraping page 6 of 20\n",
      "    ğŸ“„ Scraping page 7 of 20\n",
      "    ğŸ“„ Scraping page 8 of 20\n",
      "    ğŸ“„ Scraping page 9 of 20\n",
      "    ğŸ“„ Scraping page 10 of 20\n",
      "    ğŸ“„ Scraping page 11 of 20\n",
      "    ğŸ“„ Scraping page 12 of 20\n",
      "    ğŸ“„ Scraping page 13 of 20\n",
      "    ğŸ“„ Scraping page 14 of 20\n",
      "    ğŸ“„ Scraping page 15 of 20\n",
      "    ğŸ“„ Scraping page 16 of 20\n",
      "    ğŸ“„ Scraping page 17 of 20\n",
      "    ğŸ“„ Scraping page 18 of 20\n",
      "    ğŸ“„ Scraping page 19 of 20\n",
      "    ğŸ“„ Scraping page 20 of 20\n",
      "  ğŸ”¤ Scraping letter: u (4 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 4\n",
      "    ğŸ“„ Scraping page 2 of 4\n",
      "    ğŸ“„ Scraping page 3 of 4\n",
      "    ğŸ“„ Scraping page 4 of 4\n",
      "  ğŸ”¤ Scraping letter: v (4 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 4\n",
      "    ğŸ“„ Scraping page 2 of 4\n",
      "    ğŸ“„ Scraping page 3 of 4\n",
      "    ğŸ“„ Scraping page 4 of 4\n",
      "  ğŸ”¤ Scraping letter: w (14 pages, 334 entries)\n",
      "    ğŸ“„ Scraping page 1 of 14\n",
      "    ğŸ“„ Scraping page 2 of 14\n",
      "    ğŸ“„ Scraping page 3 of 14\n",
      "    ğŸ“„ Scraping page 4 of 14\n",
      "    ğŸ“„ Scraping page 5 of 14\n",
      "    ğŸ“„ Scraping page 6 of 14\n",
      "    ğŸ“„ Scraping page 7 of 14\n",
      "    ğŸ“„ Scraping page 8 of 14\n",
      "    ğŸ“„ Scraping page 9 of 14\n",
      "    ğŸ“„ Scraping page 10 of 14\n",
      "    ğŸ“„ Scraping page 11 of 14\n",
      "    ğŸ“„ Scraping page 12 of 14\n",
      "    ğŸ“„ Scraping page 13 of 14\n",
      "    ğŸ“„ Scraping page 14 of 14\n",
      "  ğŸ”¤ Scraping letter: x (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: y (3 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 3\n",
      "    ğŸ“„ Scraping page 2 of 3\n",
      "    ğŸ“„ Scraping page 3 of 3\n",
      "  ğŸ”¤ Scraping letter: z (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "ğŸ“– Scraping category: Ngiemboon\n",
      "  ğŸ”¤ Scraping letter: a (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: b (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: c (4 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 4\n",
      "    ğŸ“„ Scraping page 2 of 4\n",
      "    ğŸ“„ Scraping page 3 of 4\n",
      "    ğŸ“„ Scraping page 4 of 4\n",
      "  ğŸ”¤ Scraping letter: d (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: e (10 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 10\n",
      "    ğŸ“„ Scraping page 2 of 10\n",
      "    ğŸ“„ Scraping page 3 of 10\n",
      "    ğŸ“„ Scraping page 4 of 10\n",
      "    ğŸ“„ Scraping page 5 of 10\n",
      "    ğŸ“„ Scraping page 6 of 10\n",
      "    ğŸ“„ Scraping page 7 of 10\n",
      "    ğŸ“„ Scraping page 8 of 10\n",
      "    ğŸ“„ Scraping page 9 of 10\n",
      "    ğŸ“„ Scraping page 10 of 10\n",
      "  ğŸ”¤ Scraping letter: f (7 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 7\n",
      "    ğŸ“„ Scraping page 2 of 7\n",
      "    ğŸ“„ Scraping page 3 of 7\n",
      "    ğŸ“„ Scraping page 4 of 7\n",
      "    ğŸ“„ Scraping page 5 of 7\n",
      "    ğŸ“„ Scraping page 6 of 7\n",
      "    ğŸ“„ Scraping page 7 of 7\n",
      "  ğŸ”¤ Scraping letter: g (6 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 6\n",
      "    ğŸ“„ Scraping page 2 of 6\n",
      "    ğŸ“„ Scraping page 3 of 6\n",
      "    ğŸ“„ Scraping page 4 of 6\n",
      "    ğŸ“„ Scraping page 5 of 6\n",
      "    ğŸ“„ Scraping page 6 of 6\n",
      "  ğŸ”¤ Scraping letter: h (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: i (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: j (3 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 3\n",
      "    ğŸ“„ Scraping page 2 of 3\n",
      "    ğŸ“„ Scraping page 3 of 3\n",
      "  ğŸ”¤ Scraping letter: k (17 pages, 413 entries)\n",
      "    ğŸ“„ Scraping page 1 of 17\n",
      "    ğŸ“„ Scraping page 2 of 17\n",
      "    ğŸ“„ Scraping page 3 of 17\n",
      "    ğŸ“„ Scraping page 4 of 17\n",
      "    ğŸ“„ Scraping page 5 of 17\n",
      "    ğŸ“„ Scraping page 6 of 17\n",
      "    ğŸ“„ Scraping page 7 of 17\n",
      "    ğŸ“„ Scraping page 8 of 17\n",
      "    ğŸ“„ Scraping page 9 of 17\n",
      "    ğŸ“„ Scraping page 10 of 17\n",
      "    ğŸ“„ Scraping page 11 of 17\n",
      "    ğŸ“„ Scraping page 12 of 17\n",
      "    ğŸ“„ Scraping page 13 of 17\n",
      "    ğŸ“„ Scraping page 14 of 17\n",
      "    ğŸ“„ Scraping page 15 of 17\n",
      "    ğŸ“„ Scraping page 16 of 17\n",
      "    ğŸ“„ Scraping page 17 of 17\n",
      "  ğŸ”¤ Scraping letter: l (23 pages, 555 entries)\n",
      "    ğŸ“„ Scraping page 1 of 23\n",
      "    ğŸ“„ Scraping page 2 of 23\n",
      "    ğŸ“„ Scraping page 3 of 23\n",
      "    ğŸ“„ Scraping page 4 of 23\n",
      "    ğŸ“„ Scraping page 5 of 23\n",
      "    ğŸ“„ Scraping page 6 of 23\n",
      "    ğŸ“„ Scraping page 7 of 23\n",
      "    ğŸ“„ Scraping page 8 of 23\n",
      "    ğŸ“„ Scraping page 9 of 23\n",
      "    ğŸ“„ Scraping page 10 of 23\n",
      "    ğŸ“„ Scraping page 11 of 23\n",
      "    ğŸ“„ Scraping page 12 of 23\n",
      "    ğŸ“„ Scraping page 13 of 23\n",
      "    ğŸ“„ Scraping page 14 of 23\n",
      "    ğŸ“„ Scraping page 15 of 23\n",
      "    ğŸ“„ Scraping page 16 of 23\n",
      "    ğŸ“„ Scraping page 17 of 23\n",
      "    ğŸ“„ Scraping page 18 of 23\n",
      "    ğŸ“„ Scraping page 19 of 23\n",
      "    ğŸ“„ Scraping page 20 of 23\n",
      "    ğŸ“„ Scraping page 21 of 23\n",
      "    ğŸ“„ Scraping page 22 of 23\n",
      "    ğŸ“„ Scraping page 23 of 23\n",
      "  ğŸ”¤ Scraping letter: m (41 pages, 1015 entries)\n",
      "    ğŸ“„ Scraping page 1 of 41\n",
      "    ğŸ“„ Scraping page 2 of 41\n",
      "    ğŸ“„ Scraping page 3 of 41\n",
      "    ğŸ“„ Scraping page 4 of 41\n",
      "    ğŸ“„ Scraping page 5 of 41\n",
      "    ğŸ“„ Scraping page 6 of 41\n",
      "    ğŸ“„ Scraping page 7 of 41\n",
      "    ğŸ“„ Scraping page 8 of 41\n",
      "    ğŸ“„ Scraping page 9 of 41\n",
      "    ğŸ“„ Scraping page 10 of 41\n",
      "    ğŸ“„ Scraping page 11 of 41\n",
      "    ğŸ“„ Scraping page 12 of 41\n",
      "    ğŸ“„ Scraping page 13 of 41\n",
      "    ğŸ“„ Scraping page 14 of 41\n",
      "    ğŸ“„ Scraping page 15 of 41\n",
      "    ğŸ“„ Scraping page 16 of 41\n",
      "    ğŸ“„ Scraping page 17 of 41\n",
      "    ğŸ“„ Scraping page 18 of 41\n",
      "    ğŸ“„ Scraping page 19 of 41\n",
      "    ğŸ“„ Scraping page 20 of 41\n",
      "    ğŸ“„ Scraping page 21 of 41\n",
      "    ğŸ“„ Scraping page 22 of 41\n",
      "    ğŸ“„ Scraping page 23 of 41\n",
      "    ğŸ“„ Scraping page 24 of 41\n",
      "    ğŸ“„ Scraping page 25 of 41\n",
      "    ğŸ“„ Scraping page 26 of 41\n",
      "    ğŸ“„ Scraping page 27 of 41\n",
      "    ğŸ“„ Scraping page 28 of 41\n",
      "    ğŸ“„ Scraping page 29 of 41\n",
      "    ğŸ“„ Scraping page 30 of 41\n",
      "    ğŸ“„ Scraping page 31 of 41\n",
      "    ğŸ“„ Scraping page 32 of 41\n",
      "    ğŸ“„ Scraping page 33 of 41\n",
      "    ğŸ“„ Scraping page 34 of 41\n",
      "    ğŸ“„ Scraping page 35 of 41\n",
      "    ğŸ“„ Scraping page 36 of 41\n",
      "    ğŸ“„ Scraping page 37 of 41\n",
      "    ğŸ“„ Scraping page 38 of 41\n",
      "    ğŸ“„ Scraping page 39 of 41\n",
      "    ğŸ“„ Scraping page 40 of 41\n",
      "    ğŸ“„ Scraping page 41 of 41\n",
      "  ğŸ”¤ Scraping letter: n (84 pages, 2080 entries)\n",
      "    ğŸ“„ Scraping page 1 of 84\n",
      "    ğŸ“„ Scraping page 2 of 84\n",
      "    ğŸ“„ Scraping page 3 of 84\n",
      "    ğŸ“„ Scraping page 4 of 84\n",
      "    ğŸ“„ Scraping page 5 of 84\n",
      "    ğŸ“„ Scraping page 6 of 84\n",
      "    ğŸ“„ Scraping page 7 of 84\n",
      "    ğŸ“„ Scraping page 8 of 84\n",
      "    ğŸ“„ Scraping page 9 of 84\n",
      "    ğŸ“„ Scraping page 10 of 84\n",
      "    ğŸ“„ Scraping page 11 of 84\n",
      "    ğŸ“„ Scraping page 12 of 84\n",
      "    ğŸ“„ Scraping page 13 of 84\n",
      "    ğŸ“„ Scraping page 14 of 84\n",
      "    ğŸ“„ Scraping page 15 of 84\n",
      "    ğŸ“„ Scraping page 16 of 84\n",
      "    ğŸ“„ Scraping page 17 of 84\n",
      "    ğŸ“„ Scraping page 18 of 84\n",
      "    ğŸ“„ Scraping page 19 of 84\n",
      "    ğŸ“„ Scraping page 20 of 84\n",
      "    ğŸ“„ Scraping page 21 of 84\n",
      "    ğŸ“„ Scraping page 22 of 84\n",
      "    ğŸ“„ Scraping page 23 of 84\n",
      "    ğŸ“„ Scraping page 24 of 84\n",
      "    ğŸ“„ Scraping page 25 of 84\n",
      "    ğŸ“„ Scraping page 26 of 84\n",
      "    ğŸ“„ Scraping page 27 of 84\n",
      "    ğŸ“„ Scraping page 28 of 84\n",
      "    ğŸ“„ Scraping page 29 of 84\n",
      "    ğŸ“„ Scraping page 30 of 84\n",
      "    ğŸ“„ Scraping page 31 of 84\n",
      "    ğŸ“„ Scraping page 32 of 84\n",
      "    ğŸ“„ Scraping page 33 of 84\n",
      "    ğŸ“„ Scraping page 34 of 84\n",
      "    ğŸ“„ Scraping page 35 of 84\n",
      "    ğŸ“„ Scraping page 36 of 84\n",
      "    ğŸ“„ Scraping page 37 of 84\n",
      "    ğŸ“„ Scraping page 38 of 84\n",
      "    ğŸ“„ Scraping page 39 of 84\n",
      "    ğŸ“„ Scraping page 40 of 84\n",
      "    ğŸ“„ Scraping page 41 of 84\n",
      "    ğŸ“„ Scraping page 42 of 84\n",
      "    ğŸ“„ Scraping page 43 of 84\n",
      "    ğŸ“„ Scraping page 44 of 84\n",
      "    ğŸ“„ Scraping page 45 of 84\n",
      "    ğŸ“„ Scraping page 46 of 84\n",
      "    ğŸ“„ Scraping page 47 of 84\n",
      "    ğŸ“„ Scraping page 48 of 84\n",
      "    ğŸ“„ Scraping page 49 of 84\n",
      "    ğŸ“„ Scraping page 50 of 84\n",
      "    ğŸ“„ Scraping page 51 of 84\n",
      "    ğŸ“„ Scraping page 52 of 84\n",
      "    ğŸ“„ Scraping page 53 of 84\n",
      "    ğŸ“„ Scraping page 54 of 84\n",
      "    ğŸ“„ Scraping page 55 of 84\n",
      "    ğŸ“„ Scraping page 56 of 84\n",
      "    ğŸ“„ Scraping page 57 of 84\n",
      "    ğŸ“„ Scraping page 58 of 84\n",
      "    ğŸ“„ Scraping page 59 of 84\n",
      "    ğŸ“„ Scraping page 60 of 84\n",
      "    ğŸ“„ Scraping page 61 of 84\n",
      "    ğŸ“„ Scraping page 62 of 84\n",
      "    ğŸ“„ Scraping page 63 of 84\n",
      "    ğŸ“„ Scraping page 64 of 84\n",
      "    ğŸ“„ Scraping page 65 of 84\n",
      "    ğŸ“„ Scraping page 66 of 84\n",
      "    ğŸ“„ Scraping page 67 of 84\n",
      "    ğŸ“„ Scraping page 68 of 84\n",
      "    ğŸ“„ Scraping page 69 of 84\n",
      "    ğŸ“„ Scraping page 70 of 84\n",
      "    ğŸ“„ Scraping page 71 of 84\n",
      "    ğŸ“„ Scraping page 72 of 84\n",
      "    ğŸ“„ Scraping page 73 of 84\n",
      "    ğŸ“„ Scraping page 74 of 84\n",
      "    ğŸ“„ Scraping page 75 of 84\n",
      "    ğŸ“„ Scraping page 76 of 84\n",
      "    ğŸ“„ Scraping page 77 of 84\n",
      "    ğŸ“„ Scraping page 78 of 84\n",
      "    ğŸ“„ Scraping page 79 of 84\n",
      "    ğŸ“„ Scraping page 80 of 84\n",
      "    ğŸ“„ Scraping page 81 of 84\n",
      "    ğŸ“„ Scraping page 82 of 84\n",
      "    ğŸ“„ Scraping page 83 of 84\n",
      "    ğŸ“„ Scraping page 84 of 84\n",
      "  ğŸ”¤ Scraping letter: o (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: p (12 pages, 293 entries)\n",
      "    ğŸ“„ Scraping page 1 of 12\n",
      "    ğŸ“„ Scraping page 2 of 12\n",
      "    ğŸ“„ Scraping page 3 of 12\n",
      "    ğŸ“„ Scraping page 4 of 12\n",
      "    ğŸ“„ Scraping page 5 of 12\n",
      "    ğŸ“„ Scraping page 6 of 12\n",
      "    ğŸ“„ Scraping page 7 of 12\n",
      "    ğŸ“„ Scraping page 8 of 12\n",
      "    ğŸ“„ Scraping page 9 of 12\n",
      "    ğŸ“„ Scraping page 10 of 12\n",
      "    ğŸ“„ Scraping page 11 of 12\n",
      "    ğŸ“„ Scraping page 12 of 12\n",
      "  ğŸ”¤ Scraping letter: q (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: r (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: s (16 pages, 388 entries)\n",
      "    ğŸ“„ Scraping page 1 of 16\n",
      "    ğŸ“„ Scraping page 2 of 16\n",
      "    ğŸ“„ Scraping page 3 of 16\n",
      "    ğŸ“„ Scraping page 4 of 16\n",
      "    ğŸ“„ Scraping page 5 of 16\n",
      "    ğŸ“„ Scraping page 6 of 16\n",
      "    ğŸ“„ Scraping page 7 of 16\n",
      "    ğŸ“„ Scraping page 8 of 16\n",
      "    ğŸ“„ Scraping page 9 of 16\n",
      "    ğŸ“„ Scraping page 10 of 16\n",
      "    ğŸ“„ Scraping page 11 of 16\n",
      "    ğŸ“„ Scraping page 12 of 16\n",
      "    ğŸ“„ Scraping page 13 of 16\n",
      "    ğŸ“„ Scraping page 14 of 16\n",
      "    ğŸ“„ Scraping page 15 of 16\n",
      "    ğŸ“„ Scraping page 16 of 16\n",
      "  ğŸ”¤ Scraping letter: t (19 pages, 463 entries)\n",
      "    ğŸ“„ Scraping page 1 of 19\n",
      "    ğŸ“„ Scraping page 2 of 19\n",
      "    ğŸ“„ Scraping page 3 of 19\n",
      "    ğŸ“„ Scraping page 4 of 19\n",
      "    ğŸ“„ Scraping page 5 of 19\n",
      "    ğŸ“„ Scraping page 6 of 19\n",
      "    ğŸ“„ Scraping page 7 of 19\n",
      "    ğŸ“„ Scraping page 8 of 19\n",
      "    ğŸ“„ Scraping page 9 of 19\n",
      "    ğŸ“„ Scraping page 10 of 19\n",
      "    ğŸ“„ Scraping page 11 of 19\n",
      "    ğŸ“„ Scraping page 12 of 19\n",
      "    ğŸ“„ Scraping page 13 of 19\n",
      "    ğŸ“„ Scraping page 14 of 19\n",
      "    ğŸ“„ Scraping page 15 of 19\n",
      "    ğŸ“„ Scraping page 16 of 19\n",
      "    ğŸ“„ Scraping page 17 of 19\n",
      "    ğŸ“„ Scraping page 18 of 19\n",
      "    ğŸ“„ Scraping page 19 of 19\n",
      "  ğŸ”¤ Scraping letter: u (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: v (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: w (2 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 2\n",
      "    ğŸ“„ Scraping page 2 of 2\n",
      "  ğŸ”¤ Scraping letter: x (1 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 1\n",
      "  ğŸ”¤ Scraping letter: y (3 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 3\n",
      "    ğŸ“„ Scraping page 2 of 3\n",
      "    ğŸ“„ Scraping page 3 of 3\n",
      "  ğŸ”¤ Scraping letter: z (4 pages, 0 entries)\n",
      "    ğŸ“„ Scraping page 1 of 4\n",
      "    ğŸ“„ Scraping page 2 of 4\n",
      "    ğŸ“„ Scraping page 3 of 4\n",
      "    ğŸ“„ Scraping page 4 of 4\n",
      "âœ… Scraping completed. Data saved to ngiemboon_dictionary.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import string\n",
    "\n",
    "# Dictionary mapping directories to language categories\n",
    "LANGUAGES = {\n",
    "    \"francais\": \"French\",\n",
    "    \"browse-english\": \"English\",\n",
    "    \"browse-vernacular-english\": \"Ngiemboon\"\n",
    "}\n",
    "\n",
    "BASE_URL_FIRST_PAGE = \"https://www.webonary.org/ngiemboon/browse/{directory}/?letter={letter}&key=fr&lang=en\"\n",
    "BASE_URL_NEXT_PAGES = \"https://www.webonary.org/ngiemboon/browse/{directory}/?letter={letter}&key=fr&totalEntries={total_entries}&pagenr={page}&lang=en\"\n",
    "\n",
    "def get_total_pages_and_entries(directory, letter):\n",
    "    \"\"\"Get total number of pages and total entries for a letter in a directory.\"\"\"\n",
    "    url = BASE_URL_FIRST_PAGE.format(directory=directory, letter=letter)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"âŒ Failed to retrieve {url}\")\n",
    "        return 1, 0  # Default to 1 page, 0 total entries if failed\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract total pages from pagination info\n",
    "    page_info = soup.find(\"li\", class_=\"page_info\")\n",
    "    total_pages = 1  # Default to 1\n",
    "\n",
    "    if page_info:\n",
    "        try:\n",
    "            total_pages = int(page_info.text.strip().split(\"of\")[-1].strip())\n",
    "        except ValueError:\n",
    "            pass  # Default to 1 if parsing fails\n",
    "\n",
    "    # Extract totalEntries from page numbers\n",
    "    last_page_link = soup.find(\"li\", class_=\"space\")\n",
    "    total_entries = 0\n",
    "\n",
    "    if last_page_link:\n",
    "        try:\n",
    "            total_entries = int(last_page_link.find_previous_sibling(\"li\").a[\"href\"].split(\"totalEntries=\")[1].split(\"&\")[0])\n",
    "        except (AttributeError, IndexError, TypeError):\n",
    "            pass  # Default to 0 if parsing fails\n",
    "\n",
    "    return total_pages, total_entries\n",
    "\n",
    "def scrape_page(directory, letter, page, total_entries):\n",
    "    \"\"\"Scrape a single page for a given letter and directory.\"\"\"\n",
    "    if page == 1:\n",
    "        url = BASE_URL_FIRST_PAGE.format(directory=directory, letter=letter)\n",
    "    else:\n",
    "        url = BASE_URL_NEXT_PAGES.format(directory=directory, letter=letter, total_entries=total_entries, page=page)\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"âŒ Failed to retrieve page {page} for letter {letter} in {directory}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    entries = []\n",
    "\n",
    "    for entry in soup.find_all(\"div\", class_=\"reversalindexentry\"):\n",
    "        french_word_tag = entry.find(\"span\", lang=\"fr\")\n",
    "        ngiemboon_tags = entry.find_all(\"span\", lang=\"nnh\")\n",
    "        pos_tag = entry.find(\"span\", lang=\"en\")  # Part of speech\n",
    "\n",
    "        if french_word_tag and ngiemboon_tags:\n",
    "            french_word = french_word_tag.text.strip()\n",
    "            ngiemboon_words = [n.text.strip() for n in ngiemboon_tags]\n",
    "            pos = pos_tag.text.strip() if pos_tag else \"\"\n",
    "\n",
    "            entries.append({\n",
    "                \"Current Language Category\": LANGUAGES[directory],\n",
    "                \"word\": french_word,\n",
    "                \"Ngienmboon Language word\": ngiemboon_words[0],  # First occurrence\n",
    "                \"Example Usage\": \"\".join(ngiemboon_words) + pos\n",
    "            })\n",
    "\n",
    "    return entries\n",
    "\n",
    "def scrape_all_directories():\n",
    "    \"\"\"Scrape all letters (A-Z) for each directory and page.\"\"\"\n",
    "    all_entries = []\n",
    "    \n",
    "    for directory, language_category in LANGUAGES.items():\n",
    "        print(f\"ğŸ“– Scraping category: {language_category}\")\n",
    "\n",
    "        for letter in string.ascii_lowercase:  # Loop through a-z\n",
    "            total_pages, total_entries = get_total_pages_and_entries(directory, letter)\n",
    "            print(f\"  ğŸ”¤ Scraping letter: {letter} ({total_pages} pages, {total_entries} entries)\")\n",
    "\n",
    "            for page in range(1, total_pages + 1):\n",
    "                print(f\"    ğŸ“„ Scraping page {page} of {total_pages}\")\n",
    "                entries = scrape_page(directory, letter, page, total_entries)\n",
    "                all_entries.extend(entries)\n",
    "                time.sleep(1)  # Delay to avoid getting blocked\n",
    "\n",
    "    with open(\"ngiemboon_dictionary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_entries, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"âœ… Scraping completed. Data saved to ngiemboon_dictionary.json\")\n",
    "\n",
    "scrape_all_directories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in the JSON file: 9774\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the JSON file\n",
    "    with open(\"ngiemboon_dictionary.json\", 'r', encoding='utf-8') as f:\n",
    "        dataFinal = json.load(f)\n",
    "    # Print the total number of entries\n",
    "    print(f\"Total entries in the JSON file: {len(dataFinal)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: The file '{file_path}' is not a valid JSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entry(word):\n",
    "    for entry in dataFinal:\n",
    "        if entry[\"word\"].lower() == word.lower():\n",
    "            return entry\n",
    "    return \"Word not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Language Category': 'French', 'word': 'Bangang', 'Ngienmboon Language word': 'NgÇÅ‹', 'Example Usage': 'NgÇÅ‹n'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = \"Bangang\"\n",
    "result = find_entry(word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
